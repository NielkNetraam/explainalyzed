== Parsed Logical Plan ==
'Project ['id, 'coalesce('a.name, 'b.name) AS name#65, 'age, 'birth_date]
+- Project [id#57, name#58, age#59, name#61, birth_date#62]
   +- Join LeftOuter, (id#57 = id#60)
      :- SubqueryAlias a
      :  +- Relation [id#57,name#58,age#59] parquet
      +- SubqueryAlias b
         +- Relation [id#60,name#61,birth_date#62] parquet

== Analyzed Logical Plan ==
id: int, name: string, age: int, birth_date: date
Project [id#57, coalesce(name#58, name#61) AS name#65, age#59, birth_date#62]
+- Project [id#57, name#58, age#59, name#61, birth_date#62]
   +- Join LeftOuter, (id#57 = id#60)
      :- SubqueryAlias a
      :  +- Relation [id#57,name#58,age#59] parquet
      +- SubqueryAlias b
         +- Relation [id#60,name#61,birth_date#62] parquet

== Optimized Logical Plan ==
Project [id#57, coalesce(name#58, name#61) AS name#65, age#59, birth_date#62]
+- Join LeftOuter, (id#57 = id#60)
   :- Relation [id#57,name#58,age#59] parquet
   +- Filter isnotnull(id#60)
      +- Relation [id#60,name#61,birth_date#62] parquet

== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- Project [id#57, coalesce(name#58, name#61) AS name#65, age#59, birth_date#62]
   +- BroadcastHashJoin [id#57], [id#60], LeftOuter, BuildRight, false
      :- FileScan parquet [id#57,name#58,age#59] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/tisit/project/explainalyzed/data/tables/sample_table], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<id:int,name:string,age:int>
      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=150]
         +- Filter isnotnull(id#60)
            +- FileScan parquet [id#60,name#61,birth_date#62] Batched: true, DataFilters: [isnotnull(id#60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/tisit/project/explainalyzed/data/tables/sample_table_2], PartitionFilters: [], PushedFilters: [IsNotNull(id)], ReadSchema: struct<id:int,name:string,birth_date:date>
