== Parsed Logical Plan ==
'Project ['id, 'coalesce('a.name, 'b.name) AS name#55, 'age, 'birth_date]
+- Project [id#47, name#48, age#49, name#51, birth_date#52]
   +- Join LeftOuter, (id#47 = id#50)
      :- SubqueryAlias a
      :  +- Relation [id#47,name#48,age#49] parquet
      +- SubqueryAlias b
         +- Relation [id#50,name#51,birth_date#52] parquet

== Analyzed Logical Plan ==
id: int, name: string, age: int, birth_date: date
Project [id#47, coalesce(name#48, name#51) AS name#55, age#49, birth_date#52]
+- Project [id#47, name#48, age#49, name#51, birth_date#52]
   +- Join LeftOuter, (id#47 = id#50)
      :- SubqueryAlias a
      :  +- Relation [id#47,name#48,age#49] parquet
      +- SubqueryAlias b
         +- Relation [id#50,name#51,birth_date#52] parquet

== Optimized Logical Plan ==
Project [id#47, coalesce(name#48, name#51) AS name#55, age#49, birth_date#52]
+- Join LeftOuter, (id#47 = id#50)
   :- Relation [id#47,name#48,age#49] parquet
   +- Filter isnotnull(id#50)
      +- Relation [id#50,name#51,birth_date#52] parquet

== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- Project [id#47, coalesce(name#48, name#51) AS name#55, age#49, birth_date#52]
   +- BroadcastHashJoin [id#47], [id#50], LeftOuter, BuildRight, false
      :- FileScan parquet [id#47,name#48,age#49] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/tisit/project/explainalyzed/data/tables/sample_table], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<id:int,name:string,age:int>
      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=139]
         +- Filter isnotnull(id#50)
            +- FileScan parquet [id#50,name#51,birth_date#52] Batched: true, DataFilters: [isnotnull(id#50)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/tisit/project/explainalyzed/data/tables/sample_table_2], PartitionFilters: [], PushedFilters: [IsNotNull(id)], ReadSchema: struct<id:int,name:string,birth_date:date>
